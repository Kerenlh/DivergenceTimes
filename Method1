"Method 1:"

# Functions:
# estimate = function(xs, zs, p_guess, max_num_iter, tolerance){
#   num_iter = 0
#   lambdas = xs
#   p = p_guess
#   change_in_p = Inf
#   while (num_iter < max_num_iter & change_in_p > tolerance){
#     num_iter = num_iter+1
#     print(num_iter)
#     print(paste("p: ", p))
#     lambdas = solve_likelihood_for_lambdas(xs, zs, p, lambdas_guess=lambdas)
#     new_p = solve_likelihood_for_p(zs, lambdas, p)
#     change_in_p = abs(new_p - p)
#     p = new_p
#     }
#   if (num_iter >= max_num_iter){
#     print("Notice! not converged!")
#     p = min(p, 1)
#   }
#   return (c(p, lambdas))
# }

estimate = function(xs,zs){
  p = optimize(find_loglik_for_p, xs = xs, zs = zs, interval = c(0.01,2),maximum = TRUE)
  return(p$maximum)
}
find_loglik_for_p = function(p,xs,zs){
  lambdas = solve_likelihood_for_lambdas(xs,zs,p)
  loglik = 0
  # loglik = -sum(lambdas)+sum(xs*log(lambdas))
  for (i in 1:length(zs)){
    loglik = loglik + log(1+(-1)^zs[i]*exp(-2*lambdas[i]*p))
  }
  print(paste(p,loglik))
  return(loglik)
}

solve_likelihood_for_lambdas = function(xs, zs, p){
  n_samples = length(xs)
  lambdas = matrix(0,n_samples,1)
  for (i in c(1:n_samples)){
    lambdas[i,1] = solve_likelihood_for_lamda(xs[i], zs[i], p, lamda_guess=xs[i])
    #print(lambdas[i,1])
  }
  return (lambdas)
}

df_likelihood_lmd = function(lmd,x,p,z){
  return (abs(lmd - x + 2* p * lmd / (1 + (-1) ^ z * exp(2 * lmd * p))))
}

df_likelihood_jacobian_lmd = function(lmd){
  tmp = 1 + (2 * p * (1 + (-1) ^ z * exp(2 * lmd * p)) - (-1) ^ z * 2 * p * exp(2 * lmd * p)) / 
    (1 + (-1) ^ z * exp(2 * lmd * p)) ^ 2
  return (tmp)
}

solve_likelihood_for_lamda = function(x, z, p, lamda_guess){
  if (p > 5){
    return (x)
  }
  # lamda = scipy.optimize.fsolve(df_likelihood_lmd, fprime=df_likelihood_jacobian_lmd, x0=lamda_guess, factor=0.1)[0]
  # lamda = uniroot(function(lmd) df_likelihood_lmd(lmd,x,p,z),interval = c(-1,(lamda_guess+10)))
  lamda = optimize(df_likelihood_lmd, x = x, z = z, p = p, interval = c(max(0.01,lamda_guess-2),(lamda_guess+2)))
  return (lamda$minimum)
}

df_likelihood_p = function(p,lambdas,zs){
  # ps = 0.01*c(1:200)
  # liks = NULL
  # for (j in 1:length(ps)){
  #   p = ps[j]
    tmp = 0
    for (i in 1:length(zs)){
      tmp = tmp + log(1+(-1)^zs[i]*exp(-2*lambdas[i]*p))
    }
  #   liks[j] = tmp
  # }
  # plot(ps,liks)
  return (-tmp)
}

df_likelihood_jacobian_p = function(p){
  tmp = (-sum((lambdas ^ 2 * (-1) ^ zs * 2 * exp(lambdas * p * 2))/((-1)^zs * exp(lambdas * p * 2) + 1)^2))
  return (tmp)
}

solve_likelihood_for_p = function(zs, lambdas, p_guess){ 
  # p = scipy.optimize.fsolve(df_likelihood, fprime=df_likelihood_jacobian, x0=p_guess, factor=0.1)[0]
  # p = uniroot(df_likelihood_p,interval = c(-0.5,(p_guess+0.5)))
  p = optimize(df_likelihood_p,lambdas = lambdas, zs = zs, interval = c(0.0001, 2))
  return (p$minimum)
}

setwd("/Users/keren/Dropbox/Times/")
load("one_transition_type")
num_transitions = apply(one_tranistion_type[,1:4],1,sum)
load("good_transitions")
load("alpha")  # alpha = 0.1792652
alpha_good_transitions = alpha
load("best_eps")
eps = best_eps

lambdas = good_transitions
lambdas[which(lambdas==0)] = lambdas[which(lambdas==0)]+eps
# lambdas = rgamma(length(good_transitions),shape = alpha_good_transitions, rate = alpha_good_transitions/mean(good_transitions))

# lambdas = seq(1,1000,by=2)
# lambdas = 10*matrix(1,500,1)
# lambdas = exp(((-500):300)/1000) # sort-of gamma
p = 0.9
max_num_iter = 20
tolerance = 1e-4

n = length(lambdas)
xs = rpois(n,lambdas)
ys = rpois(n,lambda = lambdas*p)
zs = ys%%2
# plcs = which(xs!=0)
# xs = xs[plcs]
# ys = ys[plcs]
# zs = zs[plcs]

tmp = estimate(xs, zs)
print(tmp)
tmp2 = find_loglik_for_p(p,xs,zs)
print(tmp2)
